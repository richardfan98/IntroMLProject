{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richardfan98/IntroMLProject/blob/master/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RusWNOsNOog",
        "colab_type": "code",
        "outputId": "b52f3a61-6ec4-4428-aaf2-33ef3747104d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "a = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-148db4fd-f89b-4e48-ae27-19d2a015f473\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-148db4fd-f89b-4e48-ae27-19d2a015f473\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving NCAATourneyCompactResults.csv to NCAATourneyCompactResults.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H1-w8mhNeeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "regular = pd.read_csv('RegularSeasonDetailedResults.csv')\n",
        "ncaa = pd.read_csv('NCAATourneyCompactResults.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Vhi7xCNwKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#find all unique teams\n",
        "regular_season = regular.groupby('Season')\n",
        "regular2017 = regular_season.get_group(2017)\n",
        "teams2017 = list(regular2017['WTeamID'].unique()) + list(regular2017['LTeamID'].unique())\n",
        "teams2017 = np.array(teams2017)\n",
        "teams2017 = np.unique(teams2017)\n",
        "teams2017 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZedy2Z3VACK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a df that has all teams ready for data import\n",
        "df2017 = pd.DataFrame(teams2017,columns=['Team'])\n",
        "z = np.zeros([len(teams2017),1])\n",
        "df2017['Points'] = z\n",
        "df2017['FGM'], df2017['FGA'] = z, z\n",
        "df2017['FGM3'],df2017['FGA3'], df2017['FTM'], df2017['FTA'], df2017['OR'], df2017['DR'], df2017['Ast'], df2017['TO'], df2017['Stl'], df2017['Blk'], df2017['PF'] = z,z,z,z,z,z,z,z,z,z,z\n",
        "df2017['Games'] = z\n",
        "df2017 = df2017.set_index('Team')\n",
        "df2017\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfFaA7z_cxh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THFXQDzTYmqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find difference in each game\n",
        "r = regular2017.copy()\n",
        "r['Points'] = r.apply(lambda col: col.WScore - col.LScore, axis = 1)\n",
        "r['FGM'] = r.apply(lambda col: col.WFGM - col.LFGM, axis = 1)\n",
        "r['FGA'] = r.apply(lambda col: col.WFGA - col.LFGA, axis = 1)\n",
        "r['FGM3'] = r.apply(lambda col: col.WFGM3 - col.LFGM3, axis = 1)\n",
        "r['FGA3'] = r.apply(lambda col: col.WFGA3 - col.LFGA3, axis = 1)\n",
        "r['FTM'] = r.apply(lambda col: col.WFTM - col.LFTM, axis = 1)\n",
        "r['FTA'] = r.apply(lambda col: col.WFTA - col.LFTA, axis = 1)\n",
        "r['OR'] = r.apply(lambda col: col.WOR - col.LOR, axis = 1)\n",
        "r['DR'] = r.apply(lambda col: col.WDR - col.LDR, axis = 1)\n",
        "r['Ast'] = r.apply(lambda col: col.WAst - col.LAst, axis = 1)\n",
        "r['TO'] = r.apply(lambda col: col.WTO - col.LTO, axis = 1)\n",
        "r['Stl'] = r.apply(lambda col: col.WStl - col.LStl, axis = 1)\n",
        "r['Blk'] = r.apply(lambda col: col.WBlk - col.LBlk, axis = 1)\n",
        "r['PF'] = r.apply(lambda col: col.WPF - col.LPF, axis = 1)\n",
        "r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD6OEQyVbQkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#move processed season data to empty df\n",
        "for i in list(r.index):\n",
        "  win = r.loc[i]['WTeamID']\n",
        "  df2017.loc[win]['Games'] += 1\n",
        "  lose = r.loc[i]['LTeamID']\n",
        "  df2017.loc[lose]['Games'] += 1\n",
        "  for j in list(set(df2017.columns) - set(['Games'])):\n",
        "      df2017.loc[win][j] += r.loc[i][j] \n",
        "      df2017.loc[lose][j] -= r.loc[i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fW9IGEETiqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make all the data as average statistics\n",
        "df2017_avg = df2017.copy()\n",
        "df2017_avg['Points_Avg'] = df2017_avg.apply(lambda col: col.Points / col.Games, axis = 1)\n",
        "df2017_avg['FGM_Avg'] = df2017_avg.apply(lambda col: col.FGM / col.Games, axis = 1)\n",
        "df2017_avg['FGA_Avg'] = df2017_avg.apply(lambda col: col.FGA / col.Games, axis = 1)\n",
        "df2017_avg['FGM3_Avg'] = df2017_avg.apply(lambda col: col.FGM3 / col.Games, axis = 1)\n",
        "df2017_avg['FGA3_Avg'] = df2017_avg.apply(lambda col: col.FGA3 / col.Games, axis = 1)\n",
        "df2017_avg['FTM_Avg'] = df2017_avg.apply(lambda col: col.FTM / col.Games, axis = 1)\n",
        "df2017_avg['FTA_Avg'] = df2017_avg.apply(lambda col: col.FTA / col.Games, axis = 1)\n",
        "df2017_avg['OR_Avg'] = df2017_avg.apply(lambda col: col.OR / col.Games, axis = 1)\n",
        "df2017_avg['DR_Avg'] = df2017_avg.apply(lambda col: col.DR / col.Games, axis = 1)\n",
        "df2017_avg['Ast_Avg'] = df2017_avg.apply(lambda col: col.Ast / col.Games, axis = 1)\n",
        "df2017_avg['TO_Avg'] = df2017_avg.apply(lambda col: col.TO / col.Games, axis = 1)\n",
        "df2017_avg['Stl_Avg'] = df2017_avg.apply(lambda col: col.Stl / col.Games, axis = 1)\n",
        "df2017_avg['Blk_Avg'] = df2017_avg.apply(lambda col: col.Blk / col.Games, axis = 1)\n",
        "df2017_avg['PF_Avg'] = df2017_avg.apply(lambda col: col.PF / col.Games, axis = 1)\n",
        "df2017_avg = df2017_avg[['Points_Avg','FGM_Avg','FGA_Avg','FGM3_Avg','FGA3_Avg','FTM_Avg','FTA_Avg','OR_Avg','DR_Avg','Ast_Avg','TO_Avg','Stl_Avg','Blk_Avg','PF_Avg']]\n",
        "df2017_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lvckC-97aR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNw2KAVbkpJU",
        "colab_type": "code",
        "outputId": "791cb6bc-42ea-47a1-ab47-e10f3b715c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Clean ncaa data for a target column\n",
        "# Instead of winning and losing teams, we let smaller id teams to be team 1 and whether team 1 wins to be result\n",
        "ncaa1 = ncaa.copy()\n",
        "ncaa1 = ncaa1[['WTeamID','LTeamID']]\n",
        "ncaa1['Team1'] = ncaa1.apply(lambda row: min(row.WTeamID, row.LTeamID), axis =1)\n",
        "ncaa1['Team2'] = ncaa1.apply(lambda row: max(row.WTeamID, row.LTeamID), axis =1)\n",
        "ncaa1['Results'] = ncaa1.apply(lambda row: int(row.WTeamID == row.Team1), axis = 1)\n",
        "ncaa1 = ncaa1[['Team1','Team2', 'Results']]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Team1</th>\n",
              "      <th>Team2</th>\n",
              "      <th>Results</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1116</td>\n",
              "      <td>1234</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1120</td>\n",
              "      <td>1345</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1207</td>\n",
              "      <td>1250</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1229</td>\n",
              "      <td>1425</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1242</td>\n",
              "      <td>1325</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2179</th>\n",
              "      <td>1181</td>\n",
              "      <td>1242</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2180</th>\n",
              "      <td>1403</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>1260</td>\n",
              "      <td>1276</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>1242</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2183</th>\n",
              "      <td>1276</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2184 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Team1  Team2  Results\n",
              "0      1116   1234        1\n",
              "1      1120   1345        1\n",
              "2      1207   1250        1\n",
              "3      1229   1425        1\n",
              "4      1242   1325        1\n",
              "...     ...    ...      ...\n",
              "2179   1181   1242        0\n",
              "2180   1403   1437        0\n",
              "2181   1260   1276        0\n",
              "2182   1242   1437        0\n",
              "2183   1276   1437        0\n",
              "\n",
              "[2184 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX5GBNSbohH1",
        "colab_type": "code",
        "outputId": "2bbb0067-54d9-4b4e-e86b-e6f641082c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "# Put data for both teams together in one table\n",
        "zz = np.zeros([len(ncaa1),28])\n",
        "zz = pd.DataFrame(zz)\n",
        "ncaa_train = pd.concat([ncaa1,zz],axis = 1)\n",
        "ncaa_train.columns = ['Team1', 'Team2','Results','Points_Avg1', 'FGM_Avg1', 'FGA_Avg1', 'FGM3_Avg1', 'FGA3_Avg1', 'FTM_Avg1',\n",
        "       'FTA_Avg1', 'OR_Avg1', 'DR_Avg1', 'Ast_Avg1', 'TO_Avg1', 'Stl_Avg1',\n",
        "       'Blk_Avg1', 'PF_Avg1','Points_Avg2', 'FGM_Avg2', 'FGA_Avg2', 'FGM3_Avg2', 'FGA3_Avg2', 'FTM_Avg2',\n",
        "       'FTA_Avg2', 'OR_Avg2', 'DR_Avg2', 'Ast_Avg2', 'TO_Avg2', 'Stl_Avg2',\n",
        "       'Blk_Avg2', 'PF_Avg2']\n",
        "ncaa_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Team1</th>\n",
              "      <th>Team2</th>\n",
              "      <th>Results</th>\n",
              "      <th>Points_Avg1</th>\n",
              "      <th>FGM_Avg1</th>\n",
              "      <th>FGA_Avg1</th>\n",
              "      <th>FGM3_Avg1</th>\n",
              "      <th>FGA3_Avg1</th>\n",
              "      <th>FTM_Avg1</th>\n",
              "      <th>FTA_Avg1</th>\n",
              "      <th>OR_Avg1</th>\n",
              "      <th>DR_Avg1</th>\n",
              "      <th>Ast_Avg1</th>\n",
              "      <th>TO_Avg1</th>\n",
              "      <th>Stl_Avg1</th>\n",
              "      <th>Blk_Avg1</th>\n",
              "      <th>PF_Avg1</th>\n",
              "      <th>Points_Avg2</th>\n",
              "      <th>FGM_Avg2</th>\n",
              "      <th>FGA_Avg2</th>\n",
              "      <th>FGM3_Avg2</th>\n",
              "      <th>FGA3_Avg2</th>\n",
              "      <th>FTM_Avg2</th>\n",
              "      <th>FTA_Avg2</th>\n",
              "      <th>OR_Avg2</th>\n",
              "      <th>DR_Avg2</th>\n",
              "      <th>Ast_Avg2</th>\n",
              "      <th>TO_Avg2</th>\n",
              "      <th>Stl_Avg2</th>\n",
              "      <th>Blk_Avg2</th>\n",
              "      <th>PF_Avg2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1116</td>\n",
              "      <td>1234</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1120</td>\n",
              "      <td>1345</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1207</td>\n",
              "      <td>1250</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1229</td>\n",
              "      <td>1425</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1242</td>\n",
              "      <td>1325</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2179</th>\n",
              "      <td>1181</td>\n",
              "      <td>1242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2180</th>\n",
              "      <td>1403</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2181</th>\n",
              "      <td>1260</td>\n",
              "      <td>1276</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>1242</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2183</th>\n",
              "      <td>1276</td>\n",
              "      <td>1437</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2184 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Team1  Team2  Results  Points_Avg1  ...  TO_Avg2  Stl_Avg2  Blk_Avg2  PF_Avg2\n",
              "0      1116   1234        1          0.0  ...      0.0       0.0       0.0      0.0\n",
              "1      1120   1345        1          0.0  ...      0.0       0.0       0.0      0.0\n",
              "2      1207   1250        1          0.0  ...      0.0       0.0       0.0      0.0\n",
              "3      1229   1425        1          0.0  ...      0.0       0.0       0.0      0.0\n",
              "4      1242   1325        1          0.0  ...      0.0       0.0       0.0      0.0\n",
              "...     ...    ...      ...          ...  ...      ...       ...       ...      ...\n",
              "2179   1181   1242        0          0.0  ...      0.0       0.0       0.0      0.0\n",
              "2180   1403   1437        0          0.0  ...      0.0       0.0       0.0      0.0\n",
              "2181   1260   1276        0          0.0  ...      0.0       0.0       0.0      0.0\n",
              "2182   1242   1437        0          0.0  ...      0.0       0.0       0.0      0.0\n",
              "2183   1276   1437        0          0.0  ...      0.0       0.0       0.0      0.0\n",
              "\n",
              "[2184 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tzgwowdpS-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add data to game matchup table from data table\n",
        "for i in list(ncaa_train.index): \n",
        "  T1 = ncaa_train.loc[i]['Team1'] \n",
        "  T2 = ncaa_train.loc[i]['Team2'] \n",
        "  ncaa_train.loc[i,'Points_Avg1'] = df2017_avg.loc[T1,'Points_Avg']\n",
        "  ncaa_train.loc[i,'Points_Avg2'] = df2017_avg.loc[T2,'Points_Avg']\n",
        "  ncaa_train.loc[i,'FGM_Avg1'] = df2017_avg.loc[T1,'FGM_Avg']\n",
        "  ncaa_train.loc[i,'FGM_Avg2'] = df2017_avg.loc[T2,'FGM_Avg']\n",
        "  ncaa_train.loc[i,'FGA_Avg1'] = df2017_avg.loc[T1,'FGA_Avg']\n",
        "  ncaa_train.loc[i,'FGA_Avg2'] = df2017_avg.loc[T2,'FGA_Avg']\n",
        "  ncaa_train.loc[i,'FGM3_Avg1'] = df2017_avg.loc[T1,'FGM3_Avg']\n",
        "  ncaa_train.loc[i,'FGM3_Avg2'] = df2017_avg.loc[T2,'FGM3_Avg']\n",
        "  ncaa_train.loc[i,'FGA3_Avg1'] = df2017_avg.loc[T1,'FGA3_Avg']\n",
        "  ncaa_train.loc[i,'FGA3_Avg2'] = df2017_avg.loc[T2,'FGA3_Avg']\n",
        "  ncaa_train.loc[i,'FTM_Avg1'] = df2017_avg.loc[T1,'FTM_Avg']\n",
        "  ncaa_train.loc[i,'FTM_Avg2'] = df2017_avg.loc[T2,'FTM_Avg']\n",
        "  ncaa_train.loc[i,'FTA_Avg1'] = df2017_avg.loc[T1,'FTA_Avg']\n",
        "  ncaa_train.loc[i,'FTA_Avg2'] = df2017_avg.loc[T2,'FTA_Avg']\n",
        "  ncaa_train.loc[i,'OR_Avg1'] = df2017_avg.loc[T1,'OR_Avg']\n",
        "  ncaa_train.loc[i,'OR_Avg2'] = df2017_avg.loc[T2,'OR_Avg']\n",
        "  ncaa_train.loc[i,'DR_Avg1'] = df2017_avg.loc[T1,'DR_Avg']\n",
        "  ncaa_train.loc[i,'DR_Avg2'] = df2017_avg.loc[T2,'DR_Avg']\n",
        "  ncaa_train.loc[i,'Ast_Avg1'] = df2017_avg.loc[T1,'Ast_Avg']\n",
        "  ncaa_train.loc[i,'Ast_Avg2'] = df2017_avg.loc[T2,'Ast_Avg']\n",
        "  ncaa_train.loc[i,'TO_Avg1'] = df2017_avg.loc[T1,'TO_Avg']\n",
        "  ncaa_train.loc[i,'TO_Avg2'] = df2017_avg.loc[T2,'TO_Avg']\n",
        "  ncaa_train.loc[i,'Stl_Avg1'] = df2017_avg.loc[T1,'Stl_Avg']\n",
        "  ncaa_train.loc[i,'Stl_Avg2'] = df2017_avg.loc[T2,'Stl_Avg']\n",
        "  ncaa_train.loc[i,'Blk_Avg1'] = df2017_avg.loc[T1,'Blk_Avg']\n",
        "  ncaa_train.loc[i,'Blk_Avg2'] = df2017_avg.loc[T2,'Blk_Avg']\n",
        "  ncaa_train.loc[i,'PF_Avg1'] = df2017_avg.loc[T1,'PF_Avg']\n",
        "  ncaa_train.loc[i,'PF_Avg2'] = df2017_avg.loc[T2,'PF_Avg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ZAwb7q5Iy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get two teams' Stats difference \n",
        "ncaa_train['Points_Avg_Diff'] = ncaa_train.apply(lambda col: col.Points_Avg1 - col.Points_Avg2, axis = 1)\n",
        "ncaa_train['FGM_Avg_Diff'] = ncaa_train.apply(lambda col: col.FGM_Avg1 - col.FGM_Avg2, axis = 1)\n",
        "ncaa_train['FGA_Avg_Diff'] = ncaa_train.apply(lambda col: col.FGA_Avg1 - col.FGA_Avg2, axis = 1)\n",
        "ncaa_train['FGM3_Avg_Diff'] = ncaa_train.apply(lambda col: col.FGM3_Avg1 - col.FGM3_Avg2, axis = 1)\n",
        "ncaa_train['FGA3_Avg_Diff'] = ncaa_train.apply(lambda col: col.FGA3_Avg1 - col.FGA3_Avg2, axis = 1)\n",
        "ncaa_train['FTM_Avg_Diff'] = ncaa_train.apply(lambda col: col.FTM_Avg1 - col.FTM_Avg2, axis = 1)\n",
        "ncaa_train['FTA_Avg_Diff'] = ncaa_train.apply(lambda col: col.FTA_Avg1 - col.FTA_Avg2, axis = 1)\n",
        "ncaa_train['OR_Avg_Diff'] = ncaa_train.apply(lambda col: col.OR_Avg1 - col.OR_Avg2, axis = 1)\n",
        "ncaa_train['DR_Avg_Diff'] = ncaa_train.apply(lambda col: col.DR_Avg1 - col.DR_Avg2, axis = 1)\n",
        "ncaa_train['Ast_Avg_Diff'] = ncaa_train.apply(lambda col: col.Ast_Avg1 - col.Ast_Avg2, axis = 1)\n",
        "ncaa_train['TO_Avg_Diff'] = ncaa_train.apply(lambda col: col.TO_Avg1 - col.TO_Avg2, axis = 1)\n",
        "ncaa_train['Stl_Avg_Diff'] = ncaa_train.apply(lambda col: col.Stl_Avg1 - col.Stl_Avg2, axis = 1)\n",
        "ncaa_train['Blk_Avg_Diff'] = ncaa_train.apply(lambda col: col.Blk_Avg1 - col.Blk_Avg2, axis = 1)\n",
        "ncaa_train['PF_Avg_Diff'] = ncaa_train.apply(lambda col: col.PF_Avg1 - col.PF_Avg2, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNqOXXGU5R6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the same thing for 2017 to get 2018 testing data\n",
        "regular2018 = regular_season.get_group(2018)\n",
        "teams2018 = list(regular2018['WTeamID'].unique()) + list(regular2018['LTeamID'].unique())\n",
        "teams2018 = np.array(teams2018)\n",
        "teams2018 = np.unique(teams2018)\n",
        "teams2018 #find all unique teams\n",
        "\n",
        "df2018 = pd.DataFrame(teams2018,columns=['Team'])\n",
        "z = np.zeros([len(teams2018),1])\n",
        "df2018['Points'] = z\n",
        "df2018['FGM'], df2018['FGA'] = z, z\n",
        "df2018['FGM3'],df2018['FGA3'], df2018['FTM'], df2018['FTA'], df2018['OR'], df2018['DR'], df2018['Ast'], df2018['TO'], df2018['Stl'], df2018['Blk'], df2018['PF'] = z,z,z,z,z,z,z,z,z,z,z\n",
        "df2018['Games'] = z\n",
        "df2018 = df2018.set_index('Team')\n",
        "\n",
        "r1 = regular2018.copy()\n",
        "r1['Points'] = r1.apply(lambda col: col.WScore - col.LScore, axis = 1)\n",
        "r1['FGM'] = r1.apply(lambda col: col.WFGM - col.LFGM, axis = 1)\n",
        "r1['FGA'] = r1.apply(lambda col: col.WFGA - col.LFGA, axis = 1)\n",
        "r1['FGM3'] = r1.apply(lambda col: col.WFGM3 - col.LFGM3, axis = 1)\n",
        "r1['FGA3'] = r1.apply(lambda col: col.WFGA3 - col.LFGA3, axis = 1)\n",
        "r1['FTM'] = r1.apply(lambda col: col.WFTM - col.LFTM, axis = 1)\n",
        "r1['FTA'] = r1.apply(lambda col: col.WFTA - col.LFTA, axis = 1)\n",
        "r1['OR'] = r1.apply(lambda col: col.WOR - col.LOR, axis = 1)\n",
        "r1['DR'] = r1.apply(lambda col: col.WDR - col.LDR, axis = 1)\n",
        "r1['Ast'] = r1.apply(lambda col: col.WAst - col.LAst, axis = 1)\n",
        "r1['TO'] = r1.apply(lambda col: col.WTO - col.LTO, axis = 1)\n",
        "r1['Stl'] = r1.apply(lambda col: col.WStl - col.LStl, axis = 1)\n",
        "r1['Blk'] = r1.apply(lambda col: col.WBlk - col.LBlk, axis = 1)\n",
        "r1['PF'] = r1.apply(lambda col: col.WPF - col.LPF, axis = 1)\n",
        "\n",
        "for i in list(r1.index):\n",
        "  win = r1.loc[i]['WTeamID']\n",
        "  df2018.loc[win]['Games'] += 1\n",
        "  lose = r1.loc[i]['LTeamID']\n",
        "  df2018.loc[lose]['Games'] += 1\n",
        "  for j in list(set(df2018.columns) - set(['Games'])):\n",
        "      df2018.loc[win][j] += r1.loc[i][j] \n",
        "      df2018.loc[lose][j] -= r1.loc[i][j]\n",
        "\n",
        "df2018_avg = df2018.copy()\n",
        "df2018_avg['Points_Avg'] = df2018_avg.apply(lambda col: col.Points / col.Games, axis = 1)\n",
        "df2018_avg['FGM_Avg'] = df2018_avg.apply(lambda col: col.FGM / col.Games, axis = 1)\n",
        "df2018_avg['FGA_Avg'] = df2018_avg.apply(lambda col: col.FGA / col.Games, axis = 1)\n",
        "df2018_avg['FGM3_Avg'] = df2018_avg.apply(lambda col: col.FGM3 / col.Games, axis = 1)\n",
        "df2018_avg['FGA3_Avg'] = df2018_avg.apply(lambda col: col.FGA3 / col.Games, axis = 1)\n",
        "df2018_avg['FTM_Avg'] = df2018_avg.apply(lambda col: col.FTM / col.Games, axis = 1)\n",
        "df2018_avg['FTA_Avg'] = df2018_avg.apply(lambda col: col.FTA / col.Games, axis = 1)\n",
        "df2018_avg['OR_Avg'] = df2018_avg.apply(lambda col: col.OR / col.Games, axis = 1)\n",
        "df2018_avg['DR_Avg'] = df2018_avg.apply(lambda col: col.DR / col.Games, axis = 1)\n",
        "df2018_avg['Ast_Avg'] = df2018_avg.apply(lambda col: col.Ast / col.Games, axis = 1)\n",
        "df2018_avg['TO_Avg'] = df2018_avg.apply(lambda col: col.TO / col.Games, axis = 1)\n",
        "df2018_avg['Stl_Avg'] = df2018_avg.apply(lambda col: col.Stl / col.Games, axis = 1)\n",
        "df2018_avg['Blk_Avg'] = df2018_avg.apply(lambda col: col.Blk / col.Games, axis = 1)\n",
        "df2018_avg['PF_Avg'] = df2018_avg.apply(lambda col: col.PF / col.Games, axis = 1)\n",
        "df2018_avg = df2018_avg[['Points_Avg','FGM_Avg','FGA_Avg','FGM3_Avg','FGA3_Avg','FTM_Avg','FTA_Avg','OR_Avg','DR_Avg','Ast_Avg','TO_Avg','Stl_Avg','Blk_Avg','PF_Avg']]\n",
        "\n",
        "ncaa2 = ncaa.copy()\n",
        "ncaa2 = ncaa2[['WTeamID','LTeamID']]\n",
        "ncaa2['Team1'] = ncaa2.apply(lambda row: min(row.WTeamID, row.LTeamID), axis =1)\n",
        "ncaa2['Team2'] = ncaa2.apply(lambda row: max(row.WTeamID, row.LTeamID), axis =1)\n",
        "ncaa2['Results'] = ncaa2.apply(lambda row: int(row.WTeamID == row.Team1), axis = 1)\n",
        "ncaa2 = ncaa2[['Team1','Team2', 'Results']]\n",
        "\n",
        "zz1 = np.zeros([len(ncaa1),28])\n",
        "zz1 = pd.DataFrame(zz)\n",
        "ncaa_test = pd.concat([ncaa1,zz],axis = 1)\n",
        "ncaa_test.columns = ['Team1', 'Team2','Results','Points_Avg1', 'FGM_Avg1', 'FGA_Avg1', 'FGM3_Avg1', 'FGA3_Avg1', 'FTM_Avg1',\n",
        "       'FTA_Avg1', 'OR_Avg1', 'DR_Avg1', 'Ast_Avg1', 'TO_Avg1', 'Stl_Avg1',\n",
        "       'Blk_Avg1', 'PF_Avg1','Points_Avg2', 'FGM_Avg2', 'FGA_Avg2', 'FGM3_Avg2', 'FGA3_Avg2', 'FTM_Avg2',\n",
        "       'FTA_Avg2', 'OR_Avg2', 'DR_Avg2', 'Ast_Avg2', 'TO_Avg2', 'Stl_Avg2',\n",
        "       'Blk_Avg2', 'PF_Avg2']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRdxsDig8Q5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Same thing applied on test data\n",
        "for i in list(ncaa_test.index): \n",
        "  T1 = ncaa_test.loc[i]['Team1'] \n",
        "  T2 = ncaa_test.loc[i]['Team2'] \n",
        "  ncaa_test.loc[i,'Points_Avg1'] = df2018_avg.loc[T1,'Points_Avg']\n",
        "  ncaa_test.loc[i,'Points_Avg2'] = df2018_avg.loc[T2,'Points_Avg']\n",
        "  ncaa_test.loc[i,'FGM_Avg1'] = df2018_avg.loc[T1,'FGM_Avg']\n",
        "  ncaa_test.loc[i,'FGM_Avg2'] = df2018_avg.loc[T2,'FGM_Avg']\n",
        "  ncaa_test.loc[i,'FGA_Avg1'] = df2018_avg.loc[T1,'FGA_Avg']\n",
        "  ncaa_test.loc[i,'FGA_Avg2'] = df2018_avg.loc[T2,'FGA_Avg']\n",
        "  ncaa_test.loc[i,'FGM3_Avg1'] = df2018_avg.loc[T1,'FGM3_Avg']\n",
        "  ncaa_test.loc[i,'FGM3_Avg2'] = df2018_avg.loc[T2,'FGM3_Avg']\n",
        "  ncaa_test.loc[i,'FGA3_Avg1'] = df2018_avg.loc[T1,'FGA3_Avg']\n",
        "  ncaa_test.loc[i,'FGA3_Avg2'] = df2018_avg.loc[T2,'FGA3_Avg']\n",
        "  ncaa_test.loc[i,'FTM_Avg1'] = df2018_avg.loc[T1,'FTM_Avg']\n",
        "  ncaa_test.loc[i,'FTM_Avg2'] = df2018_avg.loc[T2,'FTM_Avg']\n",
        "  ncaa_test.loc[i,'FTA_Avg1'] = df2018_avg.loc[T1,'FTA_Avg']\n",
        "  ncaa_test.loc[i,'FTA_Avg2'] = df2018_avg.loc[T2,'FTA_Avg']\n",
        "  ncaa_test.loc[i,'OR_Avg1'] = df2018_avg.loc[T1,'OR_Avg']\n",
        "  ncaa_test.loc[i,'OR_Avg2'] = df2018_avg.loc[T2,'OR_Avg']\n",
        "  ncaa_test.loc[i,'DR_Avg1'] = df2018_avg.loc[T1,'DR_Avg']\n",
        "  ncaa_test.loc[i,'DR_Avg2'] = df2018_avg.loc[T2,'DR_Avg']\n",
        "  ncaa_test.loc[i,'Ast_Avg1'] = df2018_avg.loc[T1,'Ast_Avg']\n",
        "  ncaa_test.loc[i,'Ast_Avg2'] = df2018_avg.loc[T2,'Ast_Avg']\n",
        "  ncaa_test.loc[i,'TO_Avg1'] = df2018_avg.loc[T1,'TO_Avg']\n",
        "  ncaa_test.loc[i,'TO_Avg2'] = df2018_avg.loc[T2,'TO_Avg']\n",
        "  ncaa_test.loc[i,'Stl_Avg1'] = df2018_avg.loc[T1,'Stl_Avg']\n",
        "  ncaa_test.loc[i,'Stl_Avg2'] = df2018_avg.loc[T2,'Stl_Avg']\n",
        "  ncaa_test.loc[i,'Blk_Avg1'] = df2018_avg.loc[T1,'Blk_Avg']\n",
        "  ncaa_test.loc[i,'Blk_Avg2'] = df2018_avg.loc[T2,'Blk_Avg']\n",
        "  ncaa_test.loc[i,'PF_Avg1'] = df2018_avg.loc[T1,'PF_Avg']\n",
        "  ncaa_test.loc[i,'PF_Avg2'] = df2018_avg.loc[T2,'PF_Avg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StYj8-IK8iAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncaa_test['Points_Avg_Diff'] = ncaa_test.apply(lambda col: col.Points_Avg1 - col.Points_Avg2, axis = 1)\n",
        "ncaa_test['FGM_Avg_Diff'] = ncaa_test.apply(lambda col: col.FGM_Avg1 - col.FGM_Avg2, axis = 1)\n",
        "ncaa_test['FGA_Avg_Diff'] = ncaa_test.apply(lambda col: col.FGA_Avg1 - col.FGA_Avg2, axis = 1)\n",
        "ncaa_test['FGM3_Avg_Diff'] = ncaa_test.apply(lambda col: col.FGM3_Avg1 - col.FGM3_Avg2, axis = 1)\n",
        "ncaa_test['FGA3_Avg_Diff'] = ncaa_test.apply(lambda col: col.FGA3_Avg1 - col.FGA3_Avg2, axis = 1)\n",
        "ncaa_test['FTM_Avg_Diff'] = ncaa_test.apply(lambda col: col.FTM_Avg1 - col.FTM_Avg2, axis = 1)\n",
        "ncaa_test['FTA_Avg_Diff'] = ncaa_test.apply(lambda col: col.FTA_Avg1 - col.FTA_Avg2, axis = 1)\n",
        "ncaa_test['OR_Avg_Diff'] = ncaa_test.apply(lambda col: col.OR_Avg1 - col.OR_Avg2, axis = 1)\n",
        "ncaa_test['DR_Avg_Diff'] = ncaa_test.apply(lambda col: col.DR_Avg1 - col.DR_Avg2, axis = 1)\n",
        "ncaa_test['Ast_Avg_Diff'] = ncaa_test.apply(lambda col: col.Ast_Avg1 - col.Ast_Avg2, axis = 1)\n",
        "ncaa_test['TO_Avg_Diff'] = ncaa_test.apply(lambda col: col.TO_Avg1 - col.TO_Avg2, axis = 1)\n",
        "ncaa_test['Stl_Avg_Diff'] = ncaa_test.apply(lambda col: col.Stl_Avg1 - col.Stl_Avg2, axis = 1)\n",
        "ncaa_test['Blk_Avg_Diff'] = ncaa_test.apply(lambda col: col.Blk_Avg1 - col.Blk_Avg2, axis = 1)\n",
        "ncaa_test['PF_Avg_Diff'] = ncaa_test.apply(lambda col: col.PF_Avg1 - col.PF_Avg2, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyepxuAW9dhe",
        "colab_type": "code",
        "outputId": "75a766d0-9b96-4427-a776-dc9f056210b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "X_train = ncaa_train[['Points_Avg1', 'FGM_Avg1', 'FGA_Avg1', 'FGM3_Avg1', 'FGA3_Avg1', 'FTM_Avg1',\n",
        "       'FTA_Avg1', 'OR_Avg1', 'DR_Avg1', 'Ast_Avg1', 'TO_Avg1', 'Stl_Avg1',\n",
        "       'Blk_Avg1', 'PF_Avg1','Points_Avg2', 'FGM_Avg2', 'FGA_Avg2', 'FGM3_Avg2', 'FGA3_Avg2', 'FTM_Avg2',\n",
        "       'FTA_Avg2', 'OR_Avg2', 'DR_Avg2', 'Ast_Avg2', 'TO_Avg2', 'Stl_Avg2',\n",
        "       'Blk_Avg2', 'PF_Avg2']]\n",
        "y_train = ncaa_train[['Results']]\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forest = RandomForestRegressor(random_state=99)\n",
        "forest.fit(X_train, y_train) \n",
        "importances = forest.feature_importances_\n",
        "importances\n",
        "\n",
        "Attribute_importance = pd.DataFrame(importances,columns = ['Importance'], index = X_train.columns)\n",
        "Attribute_importance.plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd56492dbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAErCAYAAADQckjCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1NCLiOScGnoRkZxTQy8iknP/H7XgDm8FYVsYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOgoF9Xn-WRy",
        "colab_type": "code",
        "outputId": "00d7d375-5445-4f8c-882f-2eefdc520390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "X_train_diff = ncaa_train[['Points_Avg_Diff', 'FGM_Avg_Diff',\n",
        "       'FGA_Avg_Diff', 'FGM3_Avg_Diff', 'FGA3_Avg_Diff', 'FTM_Avg_Diff',\n",
        "       'FTA_Avg_Diff', 'OR_Avg_Diff', 'DR_Avg_Diff', 'Ast_Avg_Diff',\n",
        "       'TO_Avg_Diff', 'Stl_Avg_Diff', 'Blk_Avg_Diff', 'PF_Avg_Diff']]\n",
        "forest.fit(X_train_diff, y_train) \n",
        "importances_diff = forest.feature_importances_\n",
        "Attribute_importance_diff = pd.DataFrame(importances_diff,columns = ['Importance'], index = X_train_diff.columns)\n",
        "Attribute_importance_diff.plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd564883e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 414
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE/CAYAAABINQhPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb2ZWc070ZmY19/8BaaoAaWJcznQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1H2RcNyELc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test  = ncaa_test[['Points_Avg1', 'FGM_Avg1', 'FGA_Avg1', 'FGM3_Avg1', 'FGA3_Avg1', 'FTM_Avg1',\n",
        "       'FTA_Avg1', 'OR_Avg1', 'DR_Avg1', 'Ast_Avg1', 'TO_Avg1', 'Stl_Avg1',\n",
        "       'Blk_Avg1', 'PF_Avg1','Points_Avg2', 'FGM_Avg2', 'FGA_Avg2', 'FGM3_Avg2', 'FGA3_Avg2', 'FTM_Avg2',\n",
        "       'FTA_Avg2', 'OR_Avg2', 'DR_Avg2', 'Ast_Avg2', 'TO_Avg2', 'Stl_Avg2',\n",
        "       'Blk_Avg2', 'PF_Avg2']]\n",
        "y_test = ncaa_test[['Results']]\n",
        "X_test_diff = ncaa_test[['Points_Avg_Diff', 'FGM_Avg_Diff',\n",
        "       'FGA_Avg_Diff', 'FGM3_Avg_Diff', 'FGA3_Avg_Diff', 'FTM_Avg_Diff',\n",
        "       'FTA_Avg_Diff', 'OR_Avg_Diff', 'DR_Avg_Diff', 'Ast_Avg_Diff',\n",
        "       'TO_Avg_Diff', 'Stl_Avg_Diff', 'Blk_Avg_Diff', 'PF_Avg_Diff']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5DbDda3ECUw",
        "colab_type": "code",
        "outputId": "60e3e9ba-c7db-48da-fd56-211570a4ce13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#KNN with all diff attributes: \n",
        "#Accuracy 0.5554 @k = 5 \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "classifier = KNeighborsClassifier(n_neighbors= 20 )\n",
        "classifier.fit(X_train_diff, y_train)\n",
        "y_pred = classifier.predict(X_test_diff)\n",
        "metrics.accuracy_score(y_test, y_pred) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5837912087912088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 453
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyRha6h_HvwQ",
        "colab_type": "code",
        "outputId": "1de5ec11-90a2-4cbb-b842-7f91adae98ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#KNN with importance higher than 0.08 \n",
        "#Accuracy 0.5778 @ k = 5\n",
        "X_train_diff1 = ncaa_train[['Points_Avg_Diff','Blk_Avg_Diff','FGM_Avg_Diff']]\n",
        "X_test_diff1 = ncaa_test[['Points_Avg_Diff','Blk_Avg_Diff','FGM_Avg_Diff']]\n",
        "classifier.fit(X_train_diff1, y_train)\n",
        "y_pred1 = classifier.predict(X_test_diff1)\n",
        "metrics.accuracy_score(y_test, y_pred1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5993589743589743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztmJdsB0EuJB",
        "colab_type": "code",
        "outputId": "e0a0e82c-aab6-4864-9a5b-06628c8b5c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#RandomForest \n",
        "#Accuracy = 0.5833 @ n = 100\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 100)\n",
        "rf.fit(X_train_diff,y_train)\n",
        "y_pred_rf = rf.predict(X_test_diff)\n",
        "metrics.accuracy_score(y_test, y_pred_rf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5833333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjalhUJhK__G",
        "colab_type": "code",
        "outputId": "f9a3544f-d4ac-442c-e83a-504a70f6681a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#RandomForest \n",
        "#Accuracy = 0.5769\n",
        "rf.fit(X_train_diff1,y_train)\n",
        "y_pred_rf1 = rf.predict(X_test_diff1)\n",
        "metrics.accuracy_score(y_test, y_pred_rf1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5769230769230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 463
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F1ZnEpYLXdL",
        "colab_type": "code",
        "outputId": "d019a125-8644-4d38-f249-fd0cd8d385e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Decision Tree\n",
        "#Accuracy 0.5366\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_diff,y_train)\n",
        "y_pred_dt = dt.predict(X_test_diff)\n",
        "metrics.accuracy_score(y_test, y_pred_dt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5366300366300366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 465
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7pNfxqAL2au",
        "colab_type": "code",
        "outputId": "9bd0e094-2d84-4449-9cdd-2bfaa32d5b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Accuracy 0.5769\n",
        "dt.fit(X_train_diff1,y_train)\n",
        "y_pred_dt1 = rf.predict(X_test_diff1)\n",
        "metrics.accuracy_score(y_test, y_pred_dt1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5769230769230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 466
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88vbGnTKMIXy",
        "colab_type": "code",
        "outputId": "08982c83-b932-48af-ce66-a5c7de68cce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#SVM\n",
        "#Accuracy 0.5636\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(X_train_diff,y_train)\n",
        "y_pred_svm = svm.predict(X_test_diff)\n",
        "metrics.accuracy_score(y_test, y_pred_svm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5636446886446886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 467
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMO7jMp6McVc",
        "colab_type": "code",
        "outputId": "cff5bdbe-bb9f-4e3d-f50c-539a0e24dc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Accuracy 0.6003\n",
        "svm.fit(X_train_diff1,y_train)\n",
        "y_pred_svm1 = svm.predict(X_test_diff1)\n",
        "metrics.accuracy_score(y_test, y_pred_svm1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6002747252747253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 468
        }
      ]
    }
  ]
}